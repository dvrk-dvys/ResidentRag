services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.17.6
    container_name: es_medi_rag
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      #- ES_JAVA_OPTS=-Xms512m -Xmx512m
      - ES_JAVA_OPTS=-Xms1g -Xmx1g
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - ./data/esdata:/usr/share/elasticsearch/data:rw
    ulimits:
      memlock:
        soft: -1
        hard: -1
    healthcheck:
      test: ["CMD-SHELL", "curl -fsSL http://localhost:9200/_cluster/health | grep -Eq '\"status\":\"(green|yellow)\"'"]
      interval: 10s
      timeout: 5s
      retries: 30
      start_period: 90s #nEEDS LIKE 2 MINS TO START UP ES

  qdrant:
    image: qdrant/qdrant
    container_name: qdrant_medi_rag
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - ./data/qdrant_storage:/qdrant/storage:z

  postgres:
    image: postgres:13
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    ports:
      - "${POSTGRES_PORT:-5433}:5432"
    volumes:
      - ./data/postgres_data:/var/lib/postgresql/data

  streamlit:
    build:
      context: . #REPO ROOT
      dockerfile: Dockerfile
    env_file: .env
    environment:
      DOCKER_CONTAINER: "1"
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      SKIP_WARMUP: ${SKIP_WARMUP:-false}
      ES_URL: http://elasticsearch:9200
      QDRANT_URL: http://qdrant:6333
      #MCP_SERVER_URL: http://mcp-server:8765
    volumes:
      - ./app:/app/app         # hot-reload code
      - ./data:/app/data       # (optional) local datasets
    ports:
      - "8501:8501"
    #command: streamlit run ./app/main.py --server.port=8501 --server.address=0.0.0.0
    depends_on:
      #mcp-server:
      #  condition: service_healthy
      elasticsearch:
        condition: service_healthy
      qdrant:
        condition: service_started

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3010:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_AUTH_DISABLE_LOGIN_FORM=false
      - GF_AUTH_ANONYMOUS_ENABLED=false
      - GF_SECURITY_ALLOW_EMBEDDING=true
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_USERS_ALLOW_ORG_CREATE=false
      - GF_USERS_AUTO_ASSIGN_ORG=true
      - GF_USERS_AUTO_ASSIGN_ORG_ROLE=Viewer
      - GF_SECURITY_SECRET_KEY=${GRAFANA_SECRET_KEY:-your_secret_key_here}
    depends_on:
      - postgres

volumes:
  postgres_data:
  grafana_data:



#  mcp-server:
#    build:
#      context: .
#      dockerfile: Dockerfile.mcp
#    container_name: mcp_medi_rag
#    ports:
#      - "8765:8765"
#    environment:
#      - ES_URL=http://elasticsearch:9200
#      - QDRANT_URL=http://qdrant:6333
#      - OPENAI_API_KEY=${OPENAI_API_KEY}
#    depends_on:
#      elasticsearch:
#        condition: service_healthy
#      qdrant:
#        condition: service_started
#    healthcheck:
#      test: ["CMD", "python", "-c", "import socket; socket.create_connection(('localhost', 8765), timeout=2)"]
#      interval: 10s
#      timeout: 5s
#      retries: 3
#      start_period: 10s


#Elastic Search Health checklist

# 1) cluster health
#curl -s 'http://localhost:9200/_cluster/health?pretty'

# 2) indices
#curl -s 'http://localhost:9200/_cat/indices?v'

# 3) specific index check
#ES_INDEX=${ES_INDEX:-medical_docs}
#curl -s -o /dev/null -w '%{http_code}\n' "http://localhost:9200/${ES_INDEX}"
#curl -s "http://localhost:9200/${ES_INDEX}/_count?pretty"

# =========================================
# üîÑ Development Workflow (with volume mounts)
# =========================================
# 1. Changed Python code in /app? ‚Üí Just restart
# docker compose restart streamlit

# 2. Added new pip packages? ‚Üí Rebuild
# docker compose down && docker compose up --build -d

# 3. Changed Dockerfile/docker-compose.yml? ‚Üí Rebuild
# docker compose down && docker compose up --build -d

# 4. Something weird/cached? ‚Üí Nuclear option
# docker compose down --remove-orphans
# docker compose up --build --force-recreate -d

# =========================================
# üßπ Nuke stale Docker bits (use sparingly)
# =========================================
# Stop/remove containers, networks, orphans (keeps volumes)
# docker compose down --remove-orphans
# Remove ALL unused images/volumes/cache (global)
# docker system prune -a --volumes

# =========================================
# üîç Sanity: what code is the container running?
# =========================================
# Show resolved compose (catches bad keys / confirms build context)
# docker compose config --quiet
# Exec into streamlit container and print module file paths
# docker compose exec streamlit python - <<'PY'
# import importlib;
# print("rag_utils:", importlib.import_module('app.llm.rag_utils').__file__)
# print("openai_client:", importlib.import_module('app.llm.openai_client').__file__)
# PY
